{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet_act.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P73h7guQSEIb"
      },
      "source": [
        "# Download glove embedding\n",
        " to represent word as vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPApeCPuSDm4",
        "outputId": "714e8204-4538-4abb-f1e5-eaaf34735428"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 15:38:52--  https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53933315 (51M) [text/plain]\n",
            "Saving to: ‘glove.840B.300d.sst.txt’\n",
            "\n",
            "glove.840B.300d.sst 100%[===================>]  51.43M   194MB/s    in 0.3s    \n",
            "\n",
            "2021-09-01 15:38:53 (194 MB/s) - ‘glove.840B.300d.sst.txt’ saved [53933315/53933315]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHqgSivPSCVs"
      },
      "source": [
        "!cp glove.840B.300d.sst.txt sample_data/glove.840B.300d.sst.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABBfMYbaM9OI"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0LksJNeSMfh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.regularizers import *\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import *\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfN0CNFR-KCI"
      },
      "source": [
        "# Supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpSu2LUcSi2d"
      },
      "source": [
        "def dumpPickle(path,object_to_dump):\n",
        "\tf=open(path,'wb')\n",
        "\tpickle.dump(object_to_dump,f)\n",
        "\tf.close()\n",
        "\n",
        "#Reads an object stores at 'path'\n",
        "def readPickle(path):\n",
        "\tf=open(path,'rb')\n",
        "\tob_to_load=pickle.load(f)\n",
        "\tf.close()\n",
        "\treturn ob_to_load\n",
        "\n",
        "#Loads an embedding matrix stores at emb_pickle_path if doesn't exists a pickled file, then creates One which is initialized by normal distribution with mean and std dev of the embeddings used, if given the option to save it saves\n",
        "#the newly created embedding matrix at saveName\n",
        "def load_create_embedding_matrix(word_index,vocab_size,emb_dim,emb_path,emb_pickle_path=False,save=False,saveName=None):\n",
        "\tif not emb_pickle_path:\n",
        "\t\tembedding_dict={}\n",
        "\t\tf=open(emb_path,'rb')\n",
        "\t\tfor line in f:\n",
        "\t\t\tfields=line.split()\n",
        "\t\t\tword=fields[0]\n",
        "\t\t\tw_e=np.asarray(fields[1:],dtype='float32')\n",
        "\t\t\tembedding_dict[word]=w_e\n",
        "\t\tf.close()\n",
        "\t\tallembs=np.stack(embedding_dict.values())\n",
        "\t\temb_mean,emb_std=allembs.mean(),allembs.std()\n",
        "\t\tembedding_matrix=np.random.normal(emb_mean,emb_std,(vocab_size,emb_dim))\n",
        "\t\tfor word,index in word_index.items():\n",
        "\t\t\t#print(word)\n",
        "\t\t\tvector=embedding_dict.get(word)\n",
        "\t\t\tif vector is not None:\n",
        "\t\t\t\tembedding_matrix[index]=vector\n",
        "\t\tif save:\n",
        "\t\t\tdumpPickle(saveName,embedding_matrix)\n",
        "\telse:\n",
        "\t\tf=open(emb_pickle_path,'rb')\n",
        "\t\tembedding_matrix=pickle.load(f)\n",
        "\t\tf.close()\n",
        "\treturn embedding_matrix\n",
        "\n",
        "\n",
        "#creates a tokenizer from training data file in csv format, if there is one it loads and returns\n",
        "def load_create_tokenizer(train_data,tok_path=None,savetokenizer=False):\n",
        "\tif tok_path == None:\n",
        "\t\ttokenizer=Tokenizer()\n",
        "\t\ttokenizer.fit_on_texts(train_data)\n",
        "\t\tlen(tokenizer.word_index)\n",
        "\t\tif savetokenizer:\n",
        "\t\t\tdumpPickle('./New_Tokenizer.tkn',tokenizer)\n",
        "\telse:\n",
        "\t\ttokenizer=readPickle(tok_path)\n",
        "\treturn tokenizer\n",
        "\n",
        "def load_create_padded_data(X_train,savetokenizer,padPath=None,isPaddingDone=False,maxlen=None,tokenizer_path=None,save_new_padded_data=False,path_for_new_data=False):\n",
        "\t#print(tokenizer_path)\n",
        "\tif not isPaddingDone:\n",
        "\t\ttokenizer=load_create_tokenizer(X_train,tok_path=tokenizer_path,savetokenizer=savetokenizer)\n",
        "\t\t#word_index=tokenizer.word_index\n",
        "\t\tX_train=tokenizer.texts_to_sequences(X_train)\n",
        "\t\tX_train=pad_sequences(X_train,maxlen=maxlen)\n",
        "\t\tif save_new_padded_data:\n",
        "\t\t\tdumpPickle(path_for_new_data,X_train)\n",
        "\telse:\n",
        "\t\tX_train=readPickle(padPath)\n",
        "\treturn X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61hmhM55-TQC"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gKftH19ATHOf",
        "outputId": "85ac43c7-4dcc-483a-bbb8-58465fd16aff"
      },
      "source": [
        "data = pd.read_csv('/content/TWEET_DATA_IEEE_TCSS_-_Sheet1.csv') \n",
        "data.head()                  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RT @Bipartisanism: Katie Couric just schooled #TedCruz on gay marriage in epic fashion. http://t.co/JtNOPqqOug</th>\n",
              "      <th>STM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @stevesilberman: If you missed it: Sick bur...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jk_rowling &amp; the Never-Ending Story: With a #...</td>\n",
              "      <td>QUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @somebadideas: The emotional &amp; personal eff...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @jk_rowling: A 9-year-old Nigerian girl has...</td>\n",
              "      <td>STM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @jk_rowling: I don't want to say too much m...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  RT @Bipartisanism: Katie Couric just schooled #TedCruz on gay marriage in epic fashion. http://t.co/JtNOPqqOug  STM\n",
              "0  RT @stevesilberman: If you missed it: Sick bur...                                                              EXP\n",
              "1  @jk_rowling & the Never-Ending Story: With a #...                                                              QUE\n",
              "2  RT @somebadideas: The emotional & personal eff...                                                              EXP\n",
              "3  RT @jk_rowling: A 9-year-old Nigerian girl has...                                                              STM\n",
              "4  RT @jk_rowling: I don't want to say too much m...                                                              EXP"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTLAWhF1NbbJ"
      },
      "source": [
        "## Spliting in the ratio of 80-20 for test and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acw8ECY6LAHq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(data, test_size=0.2) \n",
        "train=pd.DataFrame(train)\n",
        "train.columns=[\"Tweet\",\"Label\"]\n",
        "test=pd.DataFrame(test)\n",
        "test.columns=[\"Tweet\",\"Label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-LqGj5K5rmN"
      },
      "source": [
        "train_Text=train[\"Tweet\"]\n",
        "train_label=train[\"Label\"]\n",
        "test_Text=test[\"Tweet\"]\n",
        "test_label=test[\"Label\"]\n",
        "\n",
        "train = [s.strip() for s in train_Text]\n",
        "test = [s.strip() for s in test_Text]\n",
        "\n",
        "text = train + test\n",
        "max1=0\n",
        "\n",
        "#making same length of all text \n",
        "for i in range(0,len(text)):\n",
        "\tdata=text[i].split(\" \")\n",
        "\tmax2=len(data)\n",
        "\tif(max2>max1):\n",
        "\t\tmax1=max2\n",
        "\n",
        "\n",
        "sequence_length = max1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwOskEIP-l75"
      },
      "source": [
        "# Create padded data and embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snxl8guZAeHH",
        "outputId": "52736a46-405e-4e41-cbb4-abcbb9cca9bc"
      },
      "source": [
        "print(\"creating data\")\n",
        "\n",
        "\n",
        "tokenizer=load_create_tokenizer(train,None,True)\n",
        "X_train=load_create_padded_data(X_train=train,savetokenizer=False,isPaddingDone=False,maxlen=sequence_length,tokenizer_path='./New_Tokenizer.tkn')\n",
        "X_test=load_create_padded_data(X_train=test,savetokenizer=False,isPaddingDone=False,maxlen=sequence_length,tokenizer_path='./New_Tokenizer.tkn')\n",
        "word_index=tokenizer.word_index\n",
        "embedding_matrix=load_create_embedding_matrix(word_index,len(word_index)+1,300,'./glove.840B.300d.sst.txt',False,True,'./Emb_Mat.mat')\n",
        "\n",
        "print(\"data created\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d1DdXfON64K"
      },
      "source": [
        "# one-hot encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgzAq5D7Agdu",
        "outputId": "0a49bd8c-1ca1-434a-c479-2336965d2deb"
      },
      "source": [
        "lbl_dict={}\n",
        "index=0\n",
        "for dial_lbls in train_label:\n",
        "\tif dial_lbls not in lbl_dict:\n",
        "\t\tlbl_dict[dial_lbls]=index\n",
        "\t\tindex=index+1\n",
        "print((lbl_dict))\n",
        "\n",
        "def create_label(label):\n",
        "\t\n",
        "    Y=[]\n",
        "    for i in label:\n",
        "    \txxx=np.zeros(len(lbl_dict)) \n",
        "    \tj=lbl_dict.get(i)\n",
        "    \txxx[j]=1\n",
        "    \tY.append(xxx)\n",
        "    return Y\n",
        "\n",
        "label = train_label\n",
        "Y_train = create_label(label)\n",
        "\n",
        "label = test_label\n",
        "Y_test = create_label(label)\n",
        "\n",
        "y_train=np.array([i for i in Y_train])\n",
        "y_test=np.array([i for i in Y_test])\n",
        "\n",
        "embedding_dim = 300"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'THT': 0, 'EXP': 1, 'STM': 2, 'QUE': 3, 'OTH': 4, 'SUG': 5, 'REQ': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c-EtKC6Wa8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64188885-b484-4a50-8e75-53904152c9a6"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5999, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "032SHPECHbOf",
        "outputId": "093ef3cd-cd82-484d-91a8-99dd9dda8682"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15263, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATxMQIyRHRtX",
        "outputId": "86b1a3df-f84f-4739-dd36-b83b43a0cc45"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egKO6LQwWaEX"
      },
      "source": [
        "# Creating CNN 1D model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9G2kbF1A-Zm",
        "outputId": "460771ff-4eba-4dff-ec62-1a452ce5d777"
      },
      "source": [
        "\n",
        "print(\"Creating Model...\")\n",
        "#input layer\n",
        "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
        "embedding = Embedding(input_dim=len(word_index)+1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=sequence_length)(inputs)\n",
        "conv_0 = Conv1D(filters=32, kernel_size=3, padding='same', kernel_initializer='normal', activation='relu')(embedding)\n",
        "maxpool_0 = MaxPooling1D(pool_size=2)(conv_0)\n",
        "dropout = Dropout(0.1)(maxpool_0)\n",
        "conv_1 = Conv1D(filters=32, kernel_size=3, padding='same', kernel_initializer='normal', activation='relu')(dropout)\n",
        "maxpool_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
        "flatten = Flatten()(maxpool_1)\n",
        "predictions = Dense(1000, activation='relu')(flatten)\n",
        "#predictions1 = output layer\n",
        "#Lets assume, correct output => [0,1,0,0,0,0,0,0]; generated output => [0.03, 0.90, 0.01, 0.02, 0.01, 0.01, 0.01, 0.01]\n",
        "predictions1 = Dense(len(lbl_dict), activation='softmax')(predictions)\n",
        "adam = Adam(lr=0.01, decay=0.3)\n",
        "model = Model(inputs=inputs, outputs=predictions1)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=4, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "predicted=model.predict(X_test)\n",
        "#print(\"DONE\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Model...\n",
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 9s 88ms/step - loss: 1.4789 - accuracy: 0.5086 - val_loss: 1.3100 - val_accuracy: 0.5253\n",
            "Epoch 2/4\n",
            "94/94 [==============================] - 8s 86ms/step - loss: 1.2487 - accuracy: 0.5401 - val_loss: 1.2564 - val_accuracy: 0.5453\n",
            "Epoch 3/4\n",
            "94/94 [==============================] - 8s 84ms/step - loss: 1.1841 - accuracy: 0.5753 - val_loss: 1.2187 - val_accuracy: 0.5647\n",
            "Epoch 4/4\n",
            "94/94 [==============================] - 8s 84ms/step - loss: 1.1328 - accuracy: 0.5951 - val_loss: 1.1863 - val_accuracy: 0.5820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJF7Sn8hBpZH",
        "outputId": "4d8ff0f0-08b0-418d-c8fb-2e673422febb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 57)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_12 (Embedding)     (None, 57, 300)           4578900   \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 57, 32)            28832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 28, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 14, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 448)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1000)              449000    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 7)                 7007      \n",
            "=================================================================\n",
            "Total params: 5,066,843\n",
            "Trainable params: 5,066,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuOsFnFQ-27y"
      },
      "source": [
        "# Evaluate CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJHUMWBfCRJ8",
        "outputId": "c79a1dfc-d0e2-4b31-9021-f3c41d1bb0f7"
      },
      "source": [
        "Y_predicted=[]\n",
        "for i in predicted:\n",
        "    pos=i.argmax()\n",
        "    Y_predicted.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "Y_test=[]\n",
        "for i in y_test:\n",
        "    pos=i.argmax()\n",
        "    Y_test.append(pos)\n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import cross_val_predict\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(accuracy_score(Y_test, Y_predicted))\n",
        "print(classification_report(Y_test, Y_predicted,digits=4,))\n",
        "print(confusion_matrix(Y_test, Y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.582\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        55\n",
            "           1     0.5833    0.9556    0.7244       788\n",
            "           2     0.5742    0.3550    0.4388       338\n",
            "           3     0.0000    0.0000    0.0000       125\n",
            "           4     0.0000    0.0000    0.0000        75\n",
            "           5     0.0000    0.0000    0.0000        73\n",
            "           6     0.0000    0.0000    0.0000        46\n",
            "\n",
            "    accuracy                         0.5820      1500\n",
            "   macro avg     0.1653    0.1872    0.1662      1500\n",
            "weighted avg     0.4358    0.5820    0.4794      1500\n",
            "\n",
            "[[  0  21  34   0   0   0   0]\n",
            " [  0 753  35   0   0   0   0]\n",
            " [  0 218 120   0   0   0   0]\n",
            " [  0 118   7   0   0   0   0]\n",
            " [  0  71   4   0   0   0   0]\n",
            " [  0  68   5   0   0   0   0]\n",
            " [  0  42   4   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK0T_ObB_BJT"
      },
      "source": [
        "# Bi-LSTM model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odxgz3q6_Pxs",
        "outputId": "e251be2d-3e28-4bfb-fab4-a2ef63f33df8"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "max_features = 20000  \n",
        "maxlen=200\n",
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embed each integer in a 128-dimensional vector\n",
        "x = layers.Embedding(max_features, 72)(inputs)\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_13 (Embedding)     (None, None, 72)          1440000   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, None, 128)         70144     \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,609,089\n",
            "Trainable params: 1,609,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlnVzpXy_Jvx"
      },
      "source": [
        "# evalute Bi-LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMdjQyelDsap",
        "outputId": "e70bca13-d157-4e7a-e06e-07290f74bd52"
      },
      "source": [
        "Y_predicted=[]\n",
        "for i in predicted:\n",
        "    pos=i.argmax()\n",
        "    Y_predicted.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "Y_test=[]\n",
        "for i in y_test:\n",
        "    pos=i.argmax()\n",
        "    Y_test.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import cross_val_predict\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(accuracy_score(Y_test, Y_predicted))\n",
        "print(classification_report(Y_test, Y_predicted,digits=4,))\n",
        "print(confusion_matrix(Y_test, Y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.582\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        55\n",
            "           1     0.5833    0.9556    0.7244       788\n",
            "           2     0.5742    0.3550    0.4388       338\n",
            "           3     0.0000    0.0000    0.0000       125\n",
            "           4     0.0000    0.0000    0.0000        75\n",
            "           5     0.0000    0.0000    0.0000        73\n",
            "           6     0.0000    0.0000    0.0000        46\n",
            "\n",
            "    accuracy                         0.5820      1500\n",
            "   macro avg     0.1653    0.1872    0.1662      1500\n",
            "weighted avg     0.4358    0.5820    0.4794      1500\n",
            "\n",
            "[[  0  21  34   0   0   0   0]\n",
            " [  0 753  35   0   0   0   0]\n",
            " [  0 218 120   0   0   0   0]\n",
            " [  0 118   7   0   0   0   0]\n",
            " [  0  71   4   0   0   0   0]\n",
            " [  0  68   5   0   0   0   0]\n",
            " [  0  42   4   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N0uKtPMp3P3"
      },
      "source": [
        "# Few incorrect samples from the test set and deduce the possible reasons for mis-classification\n",
        "\n",
        "It was a big data set tough, the sample from test case that I feel was wrong or mis-classified are \n",
        "\n",
        "*   RT @afterglow2046: Jane Austen or Charlotte Bronte?  Oh come on. That's like saying Air or water? 20 Questions with Ursula K Le Guin https\n",
        "    > CORRECT - QUE \n",
        "    || GIVEN -   STM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*    RT @neemapr: #yesallwomen bc quickest way to get rid of unwanted attn is: 'I have a boyfriend.' \n",
        "    >CORRECT - SUG ||\n",
        "    GIVEN -EXP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  RT @lolligagme: #YesAllWomen Because when I drove cross country by myself I was never scared, but most women I know get nervous in a dark place\n",
        "    >CORRECT - STM ||\n",
        "    GIVEN - QUE\n",
        "\n",
        "\n",
        "REASON -\n",
        "\n",
        "\n",
        "1. **Sarcasm** \n",
        "\n",
        "Going through the data , I realised there were many sarcastic tweets available . Here words and phrases totally gets a different meaning . which becomes a challenge to idetify.\n",
        "\n",
        "\n",
        "2. **use of synonyms** \n",
        "\n",
        "Synonyms can lead to issues similar to contextual understanding because we use many different words to express the same idea. \n",
        "\n",
        "\n",
        "3. **slang** \n",
        "\n",
        "Informal phrases, expressions, idioms, and culture-specific lingo present in various tweets which also changes the meaning of sentence.\n",
        "\n",
        "4. **Ambiguity**\n",
        "\n",
        "Even for humans this sentence alone is difficult to interpret without the context of surrounding text. simple example asking a question without using key words like \"when\" \"how\" \"where\" etc   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO9OCYS782hJ"
      },
      "source": [
        ""
      ]
    }
  ]
}